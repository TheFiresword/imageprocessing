{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os, glob, re\n",
    "import cv2\n",
    "from typing import List\n",
    "import micasense.capture as capture\n",
    "import micasense.imageutils as imageutils\n",
    "import skimage\n",
    "import numpy as np\n",
    "from skimage.transform import warp,matrix_transform,resize,FundamentalMatrixTransform,estimate_transform,ProjectiveTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adresse IP de la caméra\n",
    "CAMERA_IP = \"192.168.1.83\"\n",
    "CAPTURE_URL = f\"http://{CAMERA_IP}/capture\"\n",
    "CAPTURE_CONF_URL = f\"http://{CAMERA_IP}/config\"\n",
    "DETECT_PANNEL_URL = f\"http://{CAMERA_IP}/detect_panel\"\n",
    "\n",
    "class TeddyFlight:\n",
    "    def __init__(self, capture_interval:float = 0.9) -> None:\n",
    "        self.capture_interval = capture_interval\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def detect_pannel(self):\n",
    "        cresponse = self.capture_image(args={\"detect_panel\": True})\n",
    "        if cresponse.get(\"status\") == \"error\":\n",
    "            print(\"Camera failed to detect a pannel\\nRetrying in 3sRetrying in 3s............\")\n",
    "            time.sleep(3)\n",
    "            self.detect_pannel()\n",
    "\n",
    "\n",
    "    def set_config(self):\n",
    "        capture_conf = {\"auto_cap_mode\": \"timer\", \"timer_period\": self.capture_interval, \"audio_enable\": True}\n",
    "        response = requests.post(CAPTURE_URL, json=capture_conf)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Configuration set successfully\")\n",
    "        else:\n",
    "            print(\"Failed to configure\")\n",
    "            \n",
    "            \n",
    "    def capture_image(self, args:dict = {}):\n",
    "        presponse = requests.post(DETECT_PANNEL_URL, json={\"abort_detect_panel\": True})\n",
    "        if presponse.status_code == 200:\n",
    "            assert presponse.json().get(\"detect_panel\") == False, \"Failed to abort the pannel detection mode even though the request was successful\\nProbably an internal error\"\n",
    "        else:\n",
    "            print(\"Failed to abort the pannel detection mode\")\n",
    "            self.capture_image()\n",
    "            \n",
    "        if args == {}:\n",
    "            response = requests.get(CAPTURE_URL)\n",
    "        else:\n",
    "            response = requests.post(CAPTURE_URL, json=args)\n",
    "        if response.status_code == 200:\n",
    "            print(\"Images captured successfully\")\n",
    "        else:\n",
    "            print(\"Failed to capture images\")\n",
    "        return response.json()\n",
    "    \n",
    "    \n",
    "    def launch(self):\n",
    "        #self.detect_pannel()\n",
    "        self.set_config()\n",
    "        self.capture_image()\n",
    "        \n",
    "        # The following approach offers more flexibility on each capture but may increase the delta time between each capture\n",
    "        #while True:\n",
    "        #    self.capture_image()\n",
    "        #    time.sleep(self.capture_interval)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TeddyFlight().launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exst_warp_matrices(warp_matrices_filename: str):\n",
    "    if Path('./' + warp_matrices_filename).is_file():\n",
    "        print(\"Found existing warp matrices for camera\")\n",
    "        load_warp_matrices = np.load(warp_matrices_filename, allow_pickle=True)\n",
    "        loaded_warp_matrices = []\n",
    "        for matrix in load_warp_matrices: \n",
    "            loaded_warp_matrices.append(matrix.astype('float32'))\n",
    "        print(\"Warp matrices successfully loaded.\")\n",
    "        warp_matrices = loaded_warp_matrices\n",
    "    else:\n",
    "        print(\"No existing warp matrices found.\")\n",
    "        warp_matrices = False\n",
    "    return warp_matrices\n",
    "\n",
    "\n",
    "def save_warp_matrices(warp_matrices : list, warp_matrices_filename : str, rewrite : bool = True):\n",
    "    working_wm = warp_matrices\n",
    "    if not Path('./' + warp_matrices_filename).is_file() or rewrite:\n",
    "        temp_matrices = []\n",
    "        for x in working_wm:\n",
    "            if isinstance(x, np.ndarray):\n",
    "                temp_matrices.append(x)\n",
    "            if isinstance(x, skimage.transform._geometric.ProjectiveTransform):\n",
    "                temp_matrices.append(x.params)\n",
    "        np.save(warp_matrices_filename, np.array(temp_matrices, dtype=object), allow_pickle=True)\n",
    "        print(\"Saved to\", Path('./' + warp_matrices_filename).resolve())\n",
    "    else:\n",
    "        print(\"Matrices already exist at\",Path('./' + warp_matrices_filename).resolve())\n",
    "    return\n",
    "\n",
    "\n",
    "def save_aligned_images(im_aligned, thecapture : capture.Capture, output_dir : str, stacked : bool = True):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    band_images_names = [Path(img.path).name  for img in thecapture.images]\n",
    "    \n",
    "    if stacked:\n",
    "        # save the 5 bands as a single stacked tif file in RGB color\n",
    "        rgb_band_indices = [thecapture.band_names_lower().index('red'),\n",
    "                        thecapture.band_names_lower().index('green'),\n",
    "                        thecapture.band_names_lower().index('blue')]\n",
    "\n",
    "        # Create normalized stacks for viewing\n",
    "        im_display = np.zeros((im_aligned.shape[0],im_aligned.shape[1],im_aligned.shape[2]), dtype=np.float32)\n",
    "        im_min = np.percentile(im_aligned[:,:,rgb_band_indices].flatten(), 0.5)  # modify these percentiles to adjust contrast\n",
    "        im_max = np.percentile(im_aligned[:,:,rgb_band_indices].flatten(), 99.5)  # for many images, 0.5 and 99.5 are good values\n",
    "\n",
    "        # for rgb true color, we use the same min and max scaling across the 3 bands to \n",
    "        # maintain the \"white balance\" of the calibrated image\n",
    "        for i in rgb_band_indices:\n",
    "            im_display[:,:,i] =  imageutils.normalize(im_aligned[:,:,i], im_min, im_max)\n",
    "        rgb = im_display[:,:,rgb_band_indices]\n",
    "        stacked_rgb_img_name = f\"IMG_{thecapture.uuid}.tif\"\n",
    "        cv2.imwrite(os.path.join(output_dir, stacked_rgb_img_name), (rgb * 255).astype(np.uint8))\n",
    "    \n",
    "    else:\n",
    "        num_bands = im_aligned.shape[2]\n",
    "        for i in range(num_bands):\n",
    "            band_image = im_aligned[:, :, i]\n",
    "            filename = band_images_names[i]\n",
    "            filepath = os.path.join(output_dir, filename)\n",
    "            cv2.imwrite(filepath, band_image)\n",
    "    return\n",
    "\n",
    "\n",
    "def realign_images(set_root_path: str = \".data/0000SET/000\", \n",
    "                   panels_ids : List[str] = [\"0000\", \"0001\", \"0002\", \"0003\", \"0004\", \"0005\", \"0006\"],\n",
    "                   regenerate_matrices : bool = True, \n",
    "                   save_as_stack : bool = True):\n",
    "    \n",
    "    images_path = Path(set_root_path)\n",
    "    panels_ids = panels_ids or []\n",
    "    if not images_path.exists() or not images_path.is_dir():\n",
    "        print(f\"Le répertoire {images_path} n'existe pas ou n'est pas un répertoire.\")\n",
    "\n",
    "    captures = {}\n",
    "    panels = {}\n",
    "    for image_path in images_path.glob('IMG_*.tif'):\n",
    "        match = re.match(r'IMG_(\\d+)_\\d\\.tif', image_path.name)\n",
    "        if match:\n",
    "            capture_number = match.group(1)\n",
    "            if capture_number in panels_ids:\n",
    "                # c'est une image du panneau\n",
    "                if capture_number not in panels:\n",
    "                    panels[capture_number] = []\n",
    "                panels[capture_number].append(image_path.as_posix())\n",
    "            else:\n",
    "                # c'est une image normale\n",
    "                if capture_number not in captures:\n",
    "                    captures[capture_number] = []\n",
    "                captures[capture_number].append(image_path.as_posix())\n",
    "\n",
    "    valid_captures = {k: v for k, v in captures.items() if len(v) == 5} if captures != {} else None\n",
    "    valid_panels = {k: v for k, v in panels.items() if len(v) == 5} if panels != {} else None\n",
    "    \n",
    "    if valid_panels:\n",
    "        for capture_number, imageNames in valid_panels.items():\n",
    "            panel_capture = capture.Capture.from_filelist(imageNames)\n",
    "    \n",
    "    if valid_captures:\n",
    "        for capture_number, imageNames in valid_captures.items():\n",
    "            thecapture = capture.Capture.from_filelist(imageNames)\n",
    "            if valid_panels: img_type = \"reflectance\"\n",
    "            elif thecapture.dls_present(): img_type='reflectance'\n",
    "            else: img_type='radiance'\n",
    "            \n",
    "            cam_serial = thecapture.camera_serial\n",
    "            warp_matrices_filename = str(cam_serial) + \"_warp_matrices_opencv.npy\"\n",
    "            warp_matrices = check_exst_warp_matrices(warp_matrices_filename)\n",
    "            if warp_matrices is False or regenerate_matrices is True:\n",
    "                st = time.time()\n",
    "                pyramid_levels = 0 # for images with RigRelatives, setting this to 0 or 1 may improve alignment\n",
    "                max_alignment_iterations = 20\n",
    "                match_index = 1\n",
    "                warp_mode = cv2.MOTION_HOMOGRAPHY # MOTION_HOMOGRAPHY or MOTION_AFFINE. For Altum images only use HOMOGRAPHY\n",
    "                print(f\"Aligning images of capture {capture_number}\")\n",
    "                warp_matrices, alignment_pairs = imageutils.align_capture(thecapture,\n",
    "                                                              ref_index = match_index,\n",
    "                                                              max_iterations = max_alignment_iterations,\n",
    "                                                              warp_mode = warp_mode,\n",
    "                                                              pyramid_levels = pyramid_levels)\n",
    "                save_warp_matrices(warp_matrices, warp_matrices_filename=warp_matrices_filename, rewrite=regenerate_matrices)\n",
    "            else:\n",
    "                print(\"Using existing warp matrices...\")\n",
    "            \n",
    "            print(f\"Finished Aligning after {int(time.time() - st)} seconds\")\n",
    "            \n",
    "            cropped_dimensions, edges = imageutils.find_crop_bounds(thecapture, warp_matrices, warp_mode=warp_mode, reference_band=match_index)\n",
    "            im_aligned = thecapture.create_aligned_capture(warp_matrices=warp_matrices, motion_type=warp_mode, img_type=img_type)\n",
    "            band_images_names = [Path(imageName).name for imageName in imageNames]\n",
    "            save_aligned_images(im_aligned, thecapture, set_root_path, stacked=save_as_stack)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing warp matrices found.\n",
      "Aligning images of capture 0007\n",
      "Finished aligning band 1\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\bld\\libopencv_1698890405962\\work\\modules\\video\\src\\ecc.cpp:574: error: (-7:Iterations do not converge) NaN encountered. in function 'cv::findTransformECC'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\Junior\\anaconda3\\envs\\micasense\\lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"c:\\Users\\Junior\\Documents\\4A\\stage\\imageprocessing\\micasense\\imageutils.py\", line 250, in align\n    cc, warp_matrix = cv2.findTransformECC(grad1, grad2, warp_matrix, warp_mode, criteria, inputMask=None,\ncv2.error: OpenCV(4.8.1) D:\\bld\\libopencv_1698890405962\\work\\modules\\video\\src\\ecc.cpp:574: error: (-7:Iterations do not converge) NaN encountered. in function 'cv::findTransformECC'\n\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrealign_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_root_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/0000SET/000\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpanels_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0000\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0001\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0002\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0003\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0004\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0005\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0006\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mregenerate_matrices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_as_stack\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 116\u001b[0m, in \u001b[0;36mrealign_images\u001b[1;34m(set_root_path, panels_ids, regenerate_matrices, save_as_stack)\u001b[0m\n\u001b[0;32m    114\u001b[0m     warp_mode \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mMOTION_AFFINE \u001b[38;5;66;03m# MOTION_HOMOGRAPHY or MOTION_AFFINE. For Altum images only use HOMOGRAPHY\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAligning images of capture \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcapture_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 116\u001b[0m     warp_matrices, alignment_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mimageutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign_capture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthecapture\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mref_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmatch_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mmax_iterations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmax_alignment_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mwarp_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwarp_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mpyramid_levels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpyramid_levels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     save_warp_matrices(warp_matrices, warp_matrices_filename\u001b[38;5;241m=\u001b[39mwarp_matrices_filename, rewrite\u001b[38;5;241m=\u001b[39mregenerate_matrices)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Junior\\Documents\\4A\\stage\\imageprocessing\\micasense\\imageutils.py:327\u001b[0m, in \u001b[0;36malign_capture\u001b[1;34m(capture, ref_index, warp_mode, max_iterations, epsilon_threshold, multithreaded, debug, pyramid_levels)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multithreaded:\n\u001b[0;32m    326\u001b[0m     pool \u001b[38;5;241m=\u001b[39m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39mmultiprocessing\u001b[38;5;241m.\u001b[39mcpu_count())\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, mat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pool\u001b[38;5;241m.\u001b[39mimap_unordered(align, alignment_pairs)):\n\u001b[0;32m    328\u001b[0m         warp_matrices[mat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_index\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m mat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarp_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28mprint\u001b[39m((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished aligning band \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(mat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_index\u001b[39m\u001b[38;5;124m'\u001b[39m])))\n",
      "File \u001b[1;32mc:\\Users\\Junior\\anaconda3\\envs\\micasense\\lib\\multiprocessing\\pool.py:868\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m    867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m--> 868\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\bld\\libopencv_1698890405962\\work\\modules\\video\\src\\ecc.cpp:574: error: (-7:Iterations do not converge) NaN encountered. in function 'cv::findTransformECC'\n"
     ]
    }
   ],
   "source": [
    "realign_images(set_root_path = \"./data/0000SET/000\", panels_ids = [\"0000\", \"0001\", \"0002\", \"0003\", \"0004\", \"0005\", \"0006\"],\n",
    "                   regenerate_matrices = True, save_as_stack = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def align_image(source_image, template, iterations, eps, motion_type=cv2.MOTION_EUCLIDEAN):\n",
    "    # Initialize the warp matrix with identity matrix\n",
    "    warp_matrix_temp = np.float32([[1, 0, 0], [0, 1, 0]])\n",
    "\n",
    "    # Convert images to grayscale if they are not already\n",
    "    if len(source_image.shape) == 3:\n",
    "        source_gray = cv2.cvtColor(source_image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        source_gray = source_image.copy()\n",
    "\n",
    "    if len(template.shape) == 3:\n",
    "        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        template_gray = template.copy()\n",
    "\n",
    "    # Find ECC transformation\n",
    "    cc, warp_matrix = cv2.findTransformECC(template_gray, source_gray, warp_matrix_temp, motion_type, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, iterations, eps))\n",
    "\n",
    "    # Apply the found warp_matrix to the source image\n",
    "    if len(source_image.shape) == 3:\n",
    "        height, width, _ = source_image.shape\n",
    "    else:\n",
    "        height, width = source_image.shape\n",
    "\n",
    "    aligned_image = cv2.warpAffine(source_image, warp_matrix, (width, height), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "\n",
    "    return aligned_image, warp_matrix\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micasense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
